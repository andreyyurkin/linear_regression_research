{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1100fc1d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# 1. Генерация данных\n",
    "np.random.seed(42)\n",
    "X_train = np.random.rand(1000, 5) * 10\n",
    "y_train = 2 * X_train[:, 0] + 3 * X_train[:, 1] + np.random.normal(0, 1, 1000)\n",
    "\n",
    "X_test = np.random.rand(200, 5) * 10\n",
    "y_test = 2 * X_test[:, 0] + 3 * X_test[:, 1] + np.random.normal(0, 1, 200)\n",
    "\n",
    "# 2. Обучение CatBoost с одним деревом\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=1,  # Только одно дерево!\n",
    "    depth=3,\n",
    "    verbose=0\n",
    ")\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train leaf indices shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# 3. Получение индексов листьев (теперь будет 1000 значений)\n",
    "train_leaf_indices = cat_model.calc_leaf_indexes(Pool(X_train, y_train)).flatten()\n",
    "test_leaf_indices = cat_model.calc_leaf_indexes(Pool(X_test)).flatten()\n",
    "\n",
    "print(f\"Train leaf indices shape: {train_leaf_indices.shape}\")  # Должно быть (1000,)\n",
    "\n",
    "# 4. Сбор статистик по листьям\n",
    "leaf_stats = []\n",
    "for leaf in np.unique(train_leaf_indices):\n",
    "    mask = train_leaf_indices == leaf\n",
    "    stats = {\n",
    "        'leaf': leaf,\n",
    "        'mean_target': np.mean(y_train[mask]),\n",
    "        'mean_feature_0': np.mean(X_train[mask, 0]),\n",
    "        'mean_feature_1': np.mean(X_train[mask, 1]),\n",
    "        'mean_feature_2': np.mean(X_train[mask, 2]),\n",
    "        'mean_feature_3': np.mean(X_train[mask, 3]),\n",
    "        'mean_feature_4': np.mean(X_train[mask, 4]),\n",
    "        'n_samples': np.sum(mask),\n",
    "    }\n",
    "    leaf_stats.append(stats)\n",
    "\n",
    "leaf_stats_df = pd.DataFrame(leaf_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leaf</th>\n",
       "      <th>mean_target</th>\n",
       "      <th>mean_feature_0</th>\n",
       "      <th>mean_feature_1</th>\n",
       "      <th>mean_feature_2</th>\n",
       "      <th>mean_feature_3</th>\n",
       "      <th>mean_feature_4</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.900817</td>\n",
       "      <td>3.875832</td>\n",
       "      <td>1.733186</td>\n",
       "      <td>4.919095</td>\n",
       "      <td>4.994874</td>\n",
       "      <td>4.723027</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23.633672</td>\n",
       "      <td>3.715625</td>\n",
       "      <td>5.421846</td>\n",
       "      <td>4.699635</td>\n",
       "      <td>4.826793</td>\n",
       "      <td>5.117173</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.263814</td>\n",
       "      <td>8.893280</td>\n",
       "      <td>1.761219</td>\n",
       "      <td>4.964224</td>\n",
       "      <td>5.016133</td>\n",
       "      <td>5.646535</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.186297</td>\n",
       "      <td>8.865991</td>\n",
       "      <td>5.468064</td>\n",
       "      <td>4.829285</td>\n",
       "      <td>4.810160</td>\n",
       "      <td>5.361096</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33.143875</td>\n",
       "      <td>3.699811</td>\n",
       "      <td>8.640388</td>\n",
       "      <td>5.000113</td>\n",
       "      <td>5.126025</td>\n",
       "      <td>4.987717</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>43.233117</td>\n",
       "      <td>8.777782</td>\n",
       "      <td>8.572662</td>\n",
       "      <td>5.220030</td>\n",
       "      <td>5.129270</td>\n",
       "      <td>4.504011</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   leaf  mean_target  mean_feature_0  mean_feature_1  mean_feature_2  \\\n",
       "0     0    12.900817        3.875832        1.733186        4.919095   \n",
       "1     1    23.633672        3.715625        5.421846        4.699635   \n",
       "2     2    23.263814        8.893280        1.761219        4.964224   \n",
       "3     3    34.186297        8.865991        5.468064        4.829285   \n",
       "4     5    33.143875        3.699811        8.640388        5.000113   \n",
       "5     7    43.233117        8.777782        8.572662        5.220030   \n",
       "\n",
       "   mean_feature_3  mean_feature_4  n_samples  \n",
       "0        4.994874        4.723027        281  \n",
       "1        4.826793        5.117173        260  \n",
       "2        5.016133        5.646535         90  \n",
       "3        4.810160        5.361096         75  \n",
       "4        5.126025        4.987717        224  \n",
       "5        5.129270        4.504011         70  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Кластеризация листьев\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "leaf_stats_df['cluster'] = kmeans.fit_predict(leaf_stats_df[['mean_target', 'mean_feature_0']])\n",
    "\n",
    "# 6. Сопоставление кластеров\n",
    "train_data = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(5)])\n",
    "train_data['target'] = y_train\n",
    "train_data['leaf'] = train_leaf_indices\n",
    "train_data = train_data.merge(leaf_stats_df[['leaf', 'cluster']], on='leaf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Обучение линейных моделей\n",
    "linear_models = {}\n",
    "for cluster in leaf_stats_df['cluster'].unique():\n",
    "    cluster_data = train_data[train_data['cluster'] == cluster]\n",
    "    X_cluster = cluster_data[[f'feature_{i}' for i in range(5)]].values\n",
    "    y_cluster = cluster_data['target'].values\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_cluster, y_cluster)\n",
    "    linear_models[cluster] = lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0812479274250786\n",
      "Test MAPE: 0.20924418567472164\n"
     ]
    }
   ],
   "source": [
    "# 8. Предсказание на тесте\n",
    "test_data = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(5)])\n",
    "test_data['leaf'] = test_leaf_indices\n",
    "test_data = test_data.merge(leaf_stats_df[['leaf', 'cluster']], on='leaf', how='left')\n",
    "\n",
    "# Заполняем пропущенные кластеры (новые листья)\n",
    "test_data['cluster'] = test_data['cluster'].fillna(-1)\n",
    "\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "for cluster in linear_models:\n",
    "    mask = test_data['cluster'] == cluster\n",
    "    test_predictions[mask] = linear_models[cluster].predict(X_test[mask])\n",
    "\n",
    "# Для новых листьев используем предсказание CatBoost\n",
    "new_leaf_mask = test_data['cluster'] == -1\n",
    "if new_leaf_mask.any():\n",
    "    test_predictions[new_leaf_mask] = cat_model.predict(X_test[new_leaf_mask])\n",
    "\n",
    "# Оценка качества\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_predictions)))\n",
    "print(\"Test MAPE:\", np.sqrt(mean_absolute_percentage_error(y_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target', ylabel='Count'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(train_data, x = 'target', hue='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0855\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Генерация данных\n",
    "np.random.seed(42)\n",
    "n_features = 5\n",
    "X_train = np.random.rand(1000, n_features) * 10\n",
    "y_train = 2*X_train[:, 0] + 3*X_train[:, 1] + np.random.normal(0, 1, 1000)\n",
    "\n",
    "X_test = np.random.rand(200, n_features) * 10\n",
    "y_test = 2*X_test[:, 0] + 3*X_test[:, 1] + np.random.normal(0, 1, 200)\n",
    "\n",
    "# 2. Обучение CatBoost (используем только 1 дерево для простоты)\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=1,  # Одно дерево для избежания проблем с размерностями\n",
    "    depth=3,\n",
    "    verbose=0\n",
    ")\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Получение индексов листьев\n",
    "train_leaf_indices = cat_model.calc_leaf_indexes(Pool(X_train, y_train)).flatten()\n",
    "test_leaf_indices = cat_model.calc_leaf_indexes(Pool(X_test)).flatten()\n",
    "\n",
    "# 4. Сбор статистики по листьям (правильная индексация)\n",
    "def get_leaf_stats(leaf_indices, X, y):\n",
    "    \"\"\"Собирает статистики по листьям с правильной индексацией\"\"\"\n",
    "    stats_list = []\n",
    "    for leaf in np.unique(leaf_indices):\n",
    "        mask = leaf_indices == leaf\n",
    "        stat = {\n",
    "            'leaf': leaf,\n",
    "            'n_samples': np.sum(mask),\n",
    "            'target_mean': np.mean(y[mask]),\n",
    "            'target_std': np.std(y[mask])\n",
    "        }\n",
    "        \n",
    "        # Добавляем статистики по всем признакам\n",
    "        for i in range(X.shape[1]):\n",
    "            stat[f'feature_{i}_mean'] = np.mean(X[mask, i])\n",
    "            stat[f'feature_{i}_std'] = np.std(X[mask, i])\n",
    "        \n",
    "        stats_list.append(stat)\n",
    "    \n",
    "    return pd.DataFrame(stats_list)\n",
    "\n",
    "leaf_stats_df = get_leaf_stats(train_leaf_indices, X_train, y_train)\n",
    "\n",
    "# 5. Кластеризация листьев\n",
    "cluster_features = [col for col in leaf_stats_df.columns \n",
    "                   if col.startswith(('target_', 'feature_'))]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "leaf_stats_df['cluster'] = kmeans.fit_predict(leaf_stats_df[cluster_features])\n",
    "\n",
    "# 6. Сопоставление кластеров с данными\n",
    "train_data = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "train_data['target'] = y_train\n",
    "train_data['leaf'] = train_leaf_indices\n",
    "train_data = train_data.merge(leaf_stats_df[['leaf', 'cluster']], on='leaf')\n",
    "\n",
    "# 7. Обучение линейных моделей для каждого кластера\n",
    "linear_models = {}\n",
    "for cluster in leaf_stats_df['cluster'].unique():\n",
    "    cluster_data = train_data[train_data['cluster'] == cluster]\n",
    "    X_cluster = cluster_data[[f'feature_{i}' for i in range(n_features)]].values\n",
    "    y_cluster = cluster_data['target'].values\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_cluster, y_cluster)\n",
    "    linear_models[cluster] = lr\n",
    "\n",
    "# 8. Предсказание на тестовой выборке\n",
    "test_data = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "test_data['leaf'] = test_leaf_indices\n",
    "test_data = test_data.merge(leaf_stats_df[['leaf', 'cluster']], on='leaf', how='left')\n",
    "\n",
    "# Обработка новых листьев (которых не было в train)\n",
    "test_data['cluster'] = test_data['cluster'].fillna(-1)\n",
    "\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "for cluster in linear_models:\n",
    "    mask = test_data['cluster'] == cluster\n",
    "    test_predictions[mask] = linear_models[cluster].predict(X_test[mask])\n",
    "\n",
    "# Для новых листьев используем предсказание CatBoost\n",
    "new_leaf_mask = test_data['cluster'] == -1\n",
    "if new_leaf_mask.any():\n",
    "    test_predictions[new_leaf_mask] = cat_model.predict(X_test[new_leaf_mask])\n",
    "\n",
    "# Оценка качества\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, test_predictions)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dy/q_kmpbjj54q1glfr1wthxzhw0000gn/T/ipykernel_73795/459742852.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['C' 'D' 'C' 'D' 'D' 'C' 'B' 'D' 'C' 'A' 'C' 'A' 'D' 'C' 'C' 'A' 'C' 'C'\n",
      " 'D' 'C' 'B' 'A' 'C' 'A' 'A' 'A' 'C' 'C' 'A' 'B' 'A' 'B' 'A' 'D' 'A' 'A'\n",
      " 'C' 'B' 'D' 'B' 'D' 'A' 'C' 'C' 'B' 'C' 'B' 'B' 'D' 'B' 'D' 'C' 'B' 'B'\n",
      " 'A' 'B' 'B' 'A' 'A' 'C' 'B' 'C' 'C' 'A' 'D' 'C' 'D' 'B' 'A' 'B' 'B' 'A'\n",
      " 'B' 'A' 'D' 'B' 'A' 'C' 'B' 'D' 'A' 'B' 'B' 'B' 'D' 'A' 'C' 'C' 'C' 'A'\n",
      " 'C' 'D' 'A' 'B' 'D' 'B' 'C' 'D' 'A' 'D' 'B' 'A' 'D' 'D' 'D' 'D' 'A' 'B'\n",
      " 'D' 'A' 'B' 'D' 'B' 'B' 'A' 'B' 'A' 'D' 'B' 'B' 'C' 'D' 'D' 'C' 'C' 'A'\n",
      " 'A' 'B' 'B' 'B' 'B' 'A' 'D' 'B' 'D' 'B' 'C' 'B' 'B' 'B' 'A' 'C' 'B' 'B'\n",
      " 'D' 'C' 'B' 'D' 'D' 'A' 'D' 'B' 'A' 'A' 'B' 'C' 'D' 'A' 'C' 'B' 'D' 'D'\n",
      " 'A' 'D' 'D' 'D' 'D' 'B' 'C' 'B' 'B' 'A' 'D' 'B' 'D' 'B' 'B' 'A' 'C' 'C'\n",
      " 'B' 'A' 'D' 'D' 'B' 'C' 'A' 'C' 'D' 'C' 'D' 'A' 'A' 'B' 'B' 'C' 'A' 'A'\n",
      " 'B' 'D' 'C' 'C' 'B' 'A' 'B' 'B' 'B' 'B' 'D' 'D' 'A' 'B' 'D' 'A' 'B' 'C'\n",
      " 'D' 'A' 'C' 'B' 'B' 'B' 'D' 'A' 'C' 'A' 'D' 'A' 'D' 'B' 'C' 'B' 'A' 'B'\n",
      " 'C' 'B' 'C' 'C' 'B' 'D' 'A' 'D' 'D' 'B' 'A' 'A' 'D' 'B' 'A' 'D' 'A' 'B'\n",
      " 'B' 'B' 'A' 'C' 'A' 'C' 'B' 'D' 'C' 'B' 'B' 'C' 'D' 'B' 'C' 'D' 'D' 'B'\n",
      " 'A' 'A' 'B' 'D' 'B' 'C' 'A' 'C' 'B' 'B' 'D' 'D' 'D' 'C' 'D' 'B' 'D' 'A'\n",
      " 'D' 'C' 'A' 'A' 'A' 'C' 'B' 'D' 'A' 'A' 'A' 'B' 'B' 'C' 'B' 'D' 'C' 'C'\n",
      " 'D' 'D' 'D' 'C' 'C' 'C' 'D' 'D' 'A' 'B' 'A' 'D' 'C' 'D' 'B' 'A' 'A' 'C'\n",
      " 'A' 'A' 'D' 'A' 'A' 'A' 'C' 'C' 'D' 'A' 'C' 'C' 'D' 'B' 'A' 'C' 'D' 'D'\n",
      " 'D' 'C' 'A' 'B' 'A' 'D' 'D' 'B' 'A' 'D' 'D' 'A' 'D' 'A' 'D' 'A' 'B' 'D'\n",
      " 'B' 'D' 'D' 'C' 'A' 'B' 'B' 'B' 'A' 'C' 'B' 'A' 'D' 'B' 'B' 'C' 'B' 'B'\n",
      " 'D' 'A' 'A' 'C' 'D' 'A' 'D' 'A' 'D' 'C' 'B' 'C' 'A' 'C' 'B' 'C' 'A' 'A'\n",
      " 'C' 'B' 'C' 'B' 'D' 'B' 'D' 'C' 'B' 'D' 'D' 'D' 'A' 'C' 'D' 'B' 'D' 'A'\n",
      " 'C' 'A' 'A' 'A' 'B' 'C' 'C' 'B' 'C' 'A' 'C' 'B' 'A' 'B' 'D' 'A' 'A' 'C'\n",
      " 'A' 'B' 'C' 'D' 'B' 'D' 'D' 'D' 'A' 'B' 'B' 'A' 'C' 'D' 'B' 'A' 'D' 'C'\n",
      " 'C' 'D' 'C' 'B' 'B' 'B' 'C' 'B' 'A' 'B' 'B' 'C' 'B' 'D' 'A' 'C' 'A' 'D'\n",
      " 'C' 'C' 'B' 'A' 'D' 'D' 'C' 'B' 'C' 'C' 'C' 'C' 'D' 'D' 'C' 'C' 'B' 'C'\n",
      " 'D' 'A' 'D' 'B' 'D' 'A' 'C' 'A' 'C' 'C' 'D' 'D' 'D' 'B' 'D' 'B' 'D' 'C'\n",
      " 'B' 'A' 'B' 'B' 'A' 'B' 'C' 'D' 'A' 'D' 'C' 'A' 'D' 'D' 'C' 'D' 'C' 'B'\n",
      " 'C' 'B' 'A' 'D' 'C' 'C' 'D' 'D' 'A' 'A' 'C' 'A' 'B' 'A' 'A' 'C' 'B' 'A'\n",
      " 'B' 'B' 'B' 'D' 'D' 'D' 'D' 'C' 'A' 'D' 'C' 'A' 'D' 'A' 'D' 'C' 'B' 'B'\n",
      " 'A' 'C' 'B' 'D' 'B' 'A' 'A' 'C' 'A' 'B' 'B' 'B' 'B' 'C' 'D' 'D' 'C' 'A'\n",
      " 'D' 'A' 'D' 'A' 'C' 'B' 'A' 'B' 'A' 'A' 'A' 'A' 'A' 'B' 'A' 'B' 'C' 'D'\n",
      " 'A' 'D' 'B' 'C' 'C' 'C' 'D' 'B' 'A' 'A' 'B' 'D' 'A' 'B' 'A' 'C' 'A' 'D'\n",
      " 'B' 'D' 'B' 'C' 'B' 'A' 'A' 'C' 'B' 'C' 'A' 'D' 'C' 'D' 'D' 'B' 'C' 'D'\n",
      " 'D' 'B' 'B' 'A' 'D' 'A' 'D' 'A' 'B' 'C' 'B' 'A' 'A' 'C' 'D' 'A' 'A' 'A'\n",
      " 'C' 'B' 'A' 'C' 'A' 'D' 'C' 'A' 'C' 'A' 'B' 'A' 'C' 'D' 'D' 'D' 'A' 'B'\n",
      " 'A' 'D' 'C' 'D' 'C' 'B' 'C' 'A' 'A' 'A' 'C' 'A' 'A' 'A' 'B' 'C' 'C' 'D'\n",
      " 'C' 'B' 'C' 'B' 'B' 'C' 'D' 'A' 'A' 'C' 'C' 'B' 'C' 'B' 'D' 'C' 'A' 'A'\n",
      " 'C' 'B' 'A' 'B' 'C' 'C' 'A' 'C' 'D' 'D' 'A' 'D' 'B' 'A' 'A' 'B' 'D' 'D'\n",
      " 'D' 'A' 'A' 'D' 'C' 'D' 'B' 'A' 'B' 'B' 'A' 'C' 'D' 'B' 'A' 'B' 'D' 'C'\n",
      " 'C' 'C' 'A' 'A' 'C' 'D' 'D' 'A' 'C' 'D' 'D' 'D' 'A' 'C' 'B' 'C' 'C' 'A'\n",
      " 'D' 'D' 'A' 'A' 'A' 'A' 'A' 'B' 'C' 'C' 'C' 'D' 'B' 'C' 'D' 'B' 'B' 'D'\n",
      " 'B' 'D' 'C' 'D' 'B' 'C' 'C' 'A' 'A' 'B' 'D' 'D' 'B' 'C' 'B' 'B' 'C' 'D'\n",
      " 'B' 'D' 'B' 'C' 'C' 'A' 'C' 'A' 'B' 'D' 'C' 'C' 'C' 'B' 'A' 'B' 'D' 'B'\n",
      " 'D' 'C' 'D' 'D' 'A' 'D' 'D' 'B' 'C' 'B' 'B' 'C' 'C' 'D' 'D' 'A' 'B' 'C'\n",
      " 'D' 'C' 'D' 'A' 'A' 'C' 'A' 'C' 'D' 'B' 'A' 'D' 'B' 'B' 'B' 'D' 'D' 'C'\n",
      " 'B' 'B' 'B' 'C' 'B' 'D' 'B' 'A' 'D' 'C' 'B' 'A' 'C' 'C' 'D' 'C' 'C' 'C'\n",
      " 'C' 'B' 'B' 'B' 'B' 'A' 'B' 'C' 'B' 'B' 'D' 'C' 'B' 'B' 'B' 'A' 'B' 'D'\n",
      " 'C' 'C' 'B' 'B' 'B' 'C' 'C' 'A' 'D' 'A' 'D' 'A' 'C' 'A' 'D' 'B' 'D' 'B'\n",
      " 'C' 'D' 'A' 'D' 'B' 'C' 'A' 'D' 'B' 'A' 'C' 'A' 'C' 'A' 'D' 'B' 'D' 'D'\n",
      " 'C' 'C' 'C' 'D' 'A' 'A' 'D' 'D' 'B' 'C' 'C' 'D' 'D' 'A' 'D' 'A' 'D' 'B'\n",
      " 'B' 'A' 'C' 'B' 'A' 'D' 'D' 'A' 'C' 'A' 'A' 'B' 'A' 'A' 'D' 'B' 'D' 'D'\n",
      " 'C' 'C' 'B' 'B' 'C' 'C' 'C' 'C' 'C' 'D' 'B' 'D' 'D' 'A' 'D' 'C' 'C' 'A'\n",
      " 'A' 'A' 'A' 'A' 'D' 'A' 'D' 'B' 'A' 'A' 'D' 'B' 'D' 'D' 'A' 'C' 'C' 'D'\n",
      " 'A' 'B' 'C' 'B' 'C' 'A' 'D' 'B' 'B' 'D']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.iloc[:, col] = np.random.choice(categories, size=n_samples)\n",
      "/var/folders/dy/q_kmpbjj54q1glfr1wthxzhw0000gn/T/ipykernel_73795/459742852.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['B' 'C' 'D' 'C' 'C' 'A' 'C' 'A' 'B' 'B' 'A' 'C' 'D' 'D' 'A' 'B' 'B' 'D'\n",
      " 'A' 'D' 'C' 'C' 'A' 'A' 'C' 'B' 'A' 'C' 'C' 'B' 'B' 'B' 'B' 'D' 'B' 'D'\n",
      " 'A' 'C' 'D' 'A' 'A' 'D' 'A' 'A' 'D' 'A' 'B' 'B' 'C' 'A' 'C' 'B' 'B' 'B'\n",
      " 'A' 'A' 'B' 'C' 'C' 'D' 'B' 'C' 'B' 'C' 'D' 'D' 'B' 'C' 'A' 'D' 'B' 'B'\n",
      " 'C' 'B' 'D' 'B' 'B' 'A' 'A' 'D' 'C' 'A' 'C' 'D' 'A' 'C' 'A' 'D' 'D' 'A'\n",
      " 'C' 'B' 'B' 'A' 'C' 'B' 'D' 'C' 'B' 'C' 'A' 'C' 'B' 'A' 'C' 'D' 'B' 'A'\n",
      " 'C' 'D' 'B' 'D' 'C' 'C' 'A' 'D' 'A' 'B' 'A' 'B' 'C' 'C' 'D' 'B' 'C' 'D'\n",
      " 'D' 'A' 'D' 'C' 'A' 'B' 'B' 'C' 'C' 'A' 'A' 'C' 'C' 'B' 'B' 'B' 'C' 'D'\n",
      " 'C' 'C' 'B' 'C' 'A' 'C' 'C' 'C' 'C' 'D' 'C' 'A' 'A' 'C' 'B' 'D' 'C' 'C'\n",
      " 'C' 'B' 'B' 'B' 'D' 'A' 'D' 'B' 'A' 'A' 'B' 'B' 'D' 'B' 'A' 'C' 'B' 'B'\n",
      " 'D' 'D' 'B' 'A' 'A' 'C' 'B' 'D' 'A' 'C' 'B' 'A' 'B' 'B' 'A' 'A' 'A' 'B'\n",
      " 'B' 'C' 'D' 'B' 'D' 'A' 'B' 'C' 'C' 'D' 'A' 'D' 'A' 'C' 'D' 'C' 'C' 'A'\n",
      " 'D' 'D' 'C' 'C' 'A' 'B' 'B' 'C' 'B' 'B' 'B' 'B' 'C' 'B' 'B' 'A' 'C' 'D'\n",
      " 'D' 'A' 'A' 'C' 'D' 'B' 'A' 'D' 'C' 'B' 'C' 'A' 'D' 'D' 'D' 'D' 'B' 'B'\n",
      " 'C' 'B' 'A' 'A' 'D' 'A' 'C' 'B' 'B' 'B' 'A' 'B' 'D' 'D' 'D' 'A' 'B' 'A'\n",
      " 'B' 'C' 'C' 'A' 'D' 'A' 'D' 'B' 'D' 'D' 'B' 'C' 'B' 'A' 'A' 'A' 'A' 'A'\n",
      " 'C' 'C' 'D' 'A' 'B' 'A' 'C' 'A' 'C' 'D' 'D' 'D' 'C' 'A' 'A' 'B' 'C' 'B'\n",
      " 'D' 'A' 'C' 'B' 'B' 'B' 'A' 'A' 'A' 'C' 'A' 'C' 'B' 'B' 'D' 'A' 'B' 'A'\n",
      " 'C' 'B' 'A' 'B' 'B' 'A' 'B' 'B' 'B' 'B' 'C' 'B' 'D' 'B' 'A' 'D' 'C' 'D'\n",
      " 'D' 'D' 'A' 'A' 'A' 'C' 'A' 'A' 'D' 'A' 'B' 'A' 'C' 'C' 'B' 'C' 'C' 'D'\n",
      " 'B' 'D' 'D' 'A' 'B' 'A' 'A' 'D' 'C' 'B' 'C' 'D' 'D' 'D' 'D' 'D' 'D' 'C'\n",
      " 'A' 'C' 'B' 'C' 'D' 'C' 'A' 'B' 'C' 'A' 'C' 'B' 'C' 'D' 'C' 'A' 'C' 'A'\n",
      " 'B' 'C' 'B' 'B' 'C' 'A' 'B' 'B' 'C' 'C' 'C' 'C' 'C' 'D' 'C' 'A' 'B' 'A'\n",
      " 'A' 'D' 'C' 'B' 'A' 'C' 'C' 'D' 'D' 'D' 'B' 'A' 'D' 'D' 'D' 'A' 'A' 'D'\n",
      " 'D' 'C' 'D' 'B' 'B' 'D' 'A' 'C' 'A' 'D' 'B' 'C' 'A' 'A' 'D' 'C' 'B' 'D'\n",
      " 'C' 'A' 'D' 'A' 'A' 'D' 'D' 'D' 'D' 'D' 'A' 'B' 'B' 'D' 'A' 'B' 'B' 'B'\n",
      " 'A' 'D' 'D' 'D' 'C' 'C' 'C' 'A' 'B' 'B' 'A' 'A' 'D' 'D' 'C' 'C' 'A' 'C'\n",
      " 'B' 'A' 'A' 'B' 'D' 'D' 'B' 'B' 'C' 'A' 'C' 'B' 'C' 'B' 'C' 'C' 'D' 'B'\n",
      " 'C' 'A' 'C' 'C' 'A' 'B' 'D' 'D' 'D' 'A' 'C' 'B' 'C' 'D' 'C' 'A' 'A' 'B'\n",
      " 'B' 'D' 'B' 'C' 'A' 'A' 'A' 'B' 'A' 'A' 'A' 'D' 'D' 'B' 'A' 'B' 'A' 'A'\n",
      " 'A' 'B' 'B' 'A' 'C' 'B' 'D' 'B' 'A' 'C' 'A' 'D' 'B' 'B' 'A' 'A' 'D' 'C'\n",
      " 'D' 'C' 'B' 'C' 'C' 'B' 'B' 'B' 'D' 'B' 'A' 'B' 'B' 'B' 'C' 'D' 'B' 'D'\n",
      " 'A' 'A' 'B' 'A' 'D' 'C' 'B' 'A' 'D' 'D' 'A' 'D' 'D' 'B' 'D' 'A' 'B' 'A'\n",
      " 'C' 'A' 'A' 'B' 'D' 'A' 'B' 'C' 'B' 'B' 'D' 'A' 'C' 'B' 'A' 'A' 'B' 'A'\n",
      " 'B' 'B' 'B' 'C' 'B' 'D' 'A' 'C' 'A' 'C' 'D' 'C' 'C' 'C' 'A' 'B' 'A' 'B'\n",
      " 'A' 'D' 'D' 'C' 'D' 'C' 'B' 'D' 'B' 'A' 'B' 'A' 'B' 'B' 'D' 'B' 'D' 'D'\n",
      " 'C' 'C' 'A' 'B' 'A' 'B' 'C' 'C' 'B' 'B' 'C' 'C' 'A' 'C' 'B' 'A' 'B' 'D'\n",
      " 'A' 'B' 'C' 'D' 'B' 'A' 'B' 'D' 'A' 'D' 'B' 'C' 'C' 'B' 'B' 'B' 'A' 'D'\n",
      " 'D' 'D' 'B' 'D' 'B' 'A' 'C' 'B' 'B' 'C' 'C' 'A' 'D' 'B' 'D' 'B' 'A' 'C'\n",
      " 'A' 'C' 'D' 'D' 'A' 'C' 'A' 'C' 'C' 'D' 'D' 'C' 'C' 'C' 'D' 'D' 'B' 'C'\n",
      " 'B' 'C' 'D' 'B' 'B' 'A' 'C' 'D' 'A' 'A' 'C' 'A' 'C' 'A' 'C' 'D' 'C' 'C'\n",
      " 'B' 'D' 'D' 'D' 'A' 'B' 'D' 'A' 'A' 'A' 'B' 'A' 'B' 'C' 'A' 'D' 'A' 'C'\n",
      " 'C' 'A' 'C' 'B' 'B' 'A' 'B' 'B' 'D' 'A' 'C' 'A' 'B' 'D' 'A' 'A' 'B' 'B'\n",
      " 'A' 'B' 'B' 'B' 'B' 'B' 'D' 'B' 'C' 'A' 'D' 'D' 'B' 'A' 'C' 'B' 'A' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'C' 'D' 'C' 'B' 'B' 'C' 'C' 'D' 'C' 'D' 'B' 'A'\n",
      " 'A' 'A' 'A' 'B' 'A' 'C' 'C' 'A' 'C' 'D' 'B' 'A' 'A' 'B' 'C' 'B' 'B' 'C'\n",
      " 'B' 'C' 'C' 'B' 'D' 'C' 'B' 'C' 'D' 'D' 'A' 'C' 'C' 'B' 'C' 'A' 'D' 'D'\n",
      " 'A' 'C' 'C' 'A' 'B' 'D' 'A' 'A' 'C' 'D' 'C' 'A' 'B' 'D' 'A' 'A' 'B' 'A'\n",
      " 'A' 'D' 'D' 'D' 'C' 'B' 'D' 'C' 'C' 'B' 'B' 'A' 'C' 'D' 'B' 'C' 'D' 'C'\n",
      " 'B' 'A' 'C' 'D' 'B' 'A' 'D' 'D' 'D' 'C' 'B' 'D' 'C' 'B' 'B' 'C' 'C' 'D'\n",
      " 'B' 'A' 'C' 'B' 'B' 'D' 'A' 'D' 'A' 'A' 'C' 'B' 'B' 'B' 'A' 'B' 'C' 'A'\n",
      " 'A' 'A' 'A' 'C' 'B' 'C' 'B' 'C' 'D' 'D' 'D' 'D' 'A' 'A' 'C' 'C' 'D' 'B'\n",
      " 'D' 'C' 'D' 'C' 'D' 'B' 'D' 'B' 'B' 'C' 'B' 'A' 'A' 'A' 'C' 'A' 'C' 'C'\n",
      " 'A' 'B' 'D' 'C' 'A' 'C' 'B' 'B' 'A' 'C' 'D' 'D' 'C' 'C' 'C' 'A' 'B' 'D'\n",
      " 'A' 'C' 'C' 'B' 'C' 'A' 'A' 'B' 'A' 'D' 'A' 'A' 'A' 'D' 'C' 'A' 'B' 'D'\n",
      " 'B' 'A' 'B' 'A' 'D' 'B' 'B' 'A' 'A' 'C']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  X.iloc[:, col] = np.random.choice(categories, size=n_samples)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from category_encoders import TargetEncoder  # Другие варианты: CatBoostEncoder, WOEEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Генерация данных с категориальными признаками\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "cat_features = [0, 2]  # Индексы категориальных признаков\n",
    "\n",
    "# Создаем синтетические данные\n",
    "X = pd.DataFrame(np.random.rand(n_samples, n_features) * 10, \n",
    "                columns=[f'feature_{i}' for i in range(n_features)])\n",
    "\n",
    "# Добавляем категориальные признаки\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "for col in cat_features:\n",
    "    X.iloc[:, col] = np.random.choice(categories, size=n_samples)\n",
    "\n",
    "# Создаем целевую переменную\n",
    "y = 2*X.iloc[:, 1] + 3*X.iloc[:, 3] + np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# 2. Разделение на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Кодирование категориальных признаков\n",
    "encoder = TargetEncoder(cols=[X.columns[i] for i in cat_features])\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# 4. Обучение CatBoost (учитываем категориальные признаки)\n",
    "cat_model = CatBoostRegressor(\n",
    "    num_trees=1,\n",
    "    depth=3,\n",
    "    cat_features=cat_features,  # Указываем индексы категориальных признаков\n",
    "    verbose=0\n",
    ")\n",
    "cat_model.fit(X_train, y_train)  # Оригинальные данные (CatBoost сам обрабатывает категории)\n",
    "\n",
    "# 5. Получение индексов листьев (на закодированных данных)\n",
    "train_leaf_indices = cat_model.calc_leaf_indexes(Pool(X_train, y_train, cat_features=cat_features)).flatten()\n",
    "test_leaf_indices = cat_model.calc_leaf_indexes(Pool(X_test, cat_features=cat_features)).flatten()\n",
    "\n",
    "# 6. Сбор статистики по листьям\n",
    "def get_leaf_stats(leaf_indices, X, y):\n",
    "    stats_list = []\n",
    "    for leaf in np.unique(leaf_indices):\n",
    "        mask = leaf_indices == leaf\n",
    "        stat = {\n",
    "            'leaf': leaf,\n",
    "            'n_samples': np.sum(mask),\n",
    "            'target_mean': np.mean(y[mask]),\n",
    "            'target_std': np.std(y[mask])\n",
    "        }\n",
    "        \n",
    "        for col in X.columns:\n",
    "            stat[f'{col}_mean'] = np.mean(X.loc[mask, col])\n",
    "            stat[f'{col}_std'] = np.std(X.loc[mask, col])\n",
    "        \n",
    "        stats_list.append(stat)\n",
    "    \n",
    "    return pd.DataFrame(stats_list)\n",
    "\n",
    "leaf_stats_df = get_leaf_stats(train_leaf_indices, X_train_encoded, y_train)\n",
    "\n",
    "# 7. Кластеризация листьев\n",
    "cluster_features = [col for col in leaf_stats_df.columns \n",
    "                   if not col in ['leaf', 'n_samples']]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "leaf_stats_df['cluster'] = kmeans.fit_predict(leaf_stats_df[cluster_features])\n",
    "\n",
    "# 8. Сопоставление кластеров\n",
    "train_data = X_train_encoded.copy()\n",
    "train_data['target'] = y_train\n",
    "train_data['leaf'] = train_leaf_indices\n",
    "train_data = train_data.merge(leaf_stats_df[['leaf', 'cluster']], on='leaf')\n",
    "\n",
    "# 9. Обучение линейных моделей\n",
    "linear_models = {}\n",
    "for cluster in leaf_stats_df['cluster'].unique():\n",
    "    cluster_data = train_data[train_data['cluster'] == cluster]\n",
    "    X_cluster = cluster_data.drop(['target', 'leaf', 'cluster'], axis=1)\n",
    "    y_cluster = cluster_data['target']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_cluster, y_cluster)\n",
    "    linear_models[cluster] = lr\n",
    "\n",
    "# 10. Предсказание на тесте\n",
    "test_data = X_test_encoded.copy()\n",
    "test_data['leaf'] = test_leaf_indices\n",
    "test_data = test_data.merge(leaf_stats_df[['leaf', 'cluster']], on='leaf', how='left')\n",
    "test_data['cluster'] = test_data['cluster'].fillna(-1)  # Новые листья\n",
    "\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "for cluster, model in linear_models.items():\n",
    "    mask = test_data['cluster'] == cluster\n",
    "    test_predictions[mask] = model.predict(test_data.loc[mask, X_test_encoded.columns])\n",
    "\n",
    "# Для новых листьев используем CatBoost\n",
    "new_leaf_mask = test_data['cluster'] == -1\n",
    "if new_leaf_mask.any():\n",
    "    test_predictions[new_leaf_mask] = cat_model.predict(X_test[new_leaf_mask])\n",
    "\n",
    "# Оценка качества\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, test_predictions)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
